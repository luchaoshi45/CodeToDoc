{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OutputParsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入依赖包，这里的 pydantic 版本为 v2\n",
    "from pydantic import BaseModel, Field, model_validator\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain.tools import tool\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.output_parsers import RetryOutputParser, OutputFixingParser\n",
    "from typing import Dict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# 使用 deepseek\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0,\n",
    "    api_key=\"sk-6b2a3015b6094e68aa2956124ad1e870\",\n",
    "    api_base=\"https://api.deepseek.com\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='由于我无法实时获取网络数据，无法提供北京当前的天气情况。不过，你可以通过以下方式轻松查询：\\n\\n1. **天气应用**：打开手机上的天气应用（如苹果天气、墨迹天气等），搜索“北京”即可查看实时天气、温度、空气质量等详细信息。\\n\\n2. **搜索引擎**：在浏览器中输入“北京实时天气”，搜索结果会直接显示当前天气状况（如晴/雨、温度、风力等）。\\n\\n3. **气象网站**：访问中国天气网（[www.weather.com.cn](http://www.weather.com.cn)）或中央气象台官网获取权威预报。\\n\\n**提示**：北京近期处于夏季，常见高温多雨天气，建议出门前关注紫外线指数和降水概率，做好防晒或防雨准备。如需更具体的穿衣或出行建议，可以告诉我你的需求哦！ ☀️🌧️', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 182, 'prompt_tokens': 8, 'total_tokens': 190, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 8}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': '1b1b1507-7176-4365-a0c2-76adc7e78b41', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--61b68fb4-9676-430c-a5d5-144362451ff6-0', usage_metadata={'input_tokens': 8, 'output_tokens': 182, 'total_tokens': 190, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"北京现在的天气怎么样？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 测试 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_weather` with `{'location': '北京'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m天气晴朗，北京当前温度为22摄氏度\u001b[0m\u001b[32;1m\u001b[1;3m北京现在的天气晴朗，温度为22摄氏度。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "最终回答： 北京现在的天气晴朗，温度为22摄氏度。\n"
     ]
    }
   ],
   "source": [
    "# =======================\n",
    "# 1. 定义工具\n",
    "# =======================\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"\n",
    "    根据地名返回模拟天气信息。\n",
    "    \"\"\"\n",
    "    return f\"天气晴朗，{location}当前温度为22摄氏度\"\n",
    "\n",
    "\n",
    "# =======================\n",
    "# 3. 创建 prompt（必须包含工具占位符）\n",
    "# =======================\n",
    "# 推荐使用官方 agent prompt 或自定义支持工具调用的 prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一个有用的助手。如果问题涉及天气，请使用工具查询后再回答。\"),\n",
    "    # 移除了 chat_history\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),  # 必须保留\n",
    "])\n",
    "\n",
    "# =======================\n",
    "# 4. 创建 Agent\n",
    "# =======================\n",
    "# 绑定工具并创建 agent\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=llm,\n",
    "    tools=[get_weather],\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# 5. 创建执行器（AgentExecutor）\n",
    "# =======================\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=[get_weather],\n",
    "    verbose=True,  # 显示中间步骤\n",
    "    handle_parsing_errors=True,  # 自动处理解析错误\n",
    ")\n",
    "\n",
    "# =======================\n",
    "# 6. 调用测试\n",
    "# =======================\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"北京现在的天气怎么样？\"\n",
    "})\n",
    "\n",
    "print(\"\\n最终回答：\", response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个名为Joke的数据模型\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"笑话中的铺垫问题，必须以？结尾\")\n",
    "    punchline: str = Field(description=\"笑话中回答铺垫问题的部分，通常是一种抖包袱方式回答铺垫问题，例如谐音、会错意等\")\n",
    "\n",
    "    # 验证器，确保setup字段以英文或中文问号结尾\n",
    "    @model_validator(mode=\"before\")\n",
    "    @classmethod\n",
    "    def question_ends_with_question_mark(cls, values: Dict) -> Dict:\n",
    "        setup = values.get(\"setup\")\n",
    "        if setup:\n",
    "            # 检查是否以英文问号(?)或中文问号(？)结尾\n",
    "            if not (setup.endswith(\"?\") or setup.endswith(\"？\")):\n",
    "                raise ValueError(\"Badly formed question! The setup must end with a question mark (? or ？).\")\n",
    "        return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: content='```json\\n{\\n  \"setup\": \"为什么数学书总是很忧郁？\",\\n  \"punchline\": \"因为它有太多的问题！\"\\n}\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 227, 'total_tokens': 259, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 192}, 'prompt_cache_hit_tokens': 192, 'prompt_cache_miss_tokens': 35}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': '8dd76625-b57f-4d99-ba1d-b777781c655c', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--91f02c02-5181-49a1-aa0b-9c43e9d00701-0' usage_metadata={'input_tokens': 227, 'output_tokens': 32, 'total_tokens': 259, 'input_token_details': {'cache_read': 192}, 'output_token_details': {}}\n",
      "Parsed output: setup='为什么数学书总是很忧郁？' punchline='因为它有太多的问题！'\n"
     ]
    }
   ],
   "source": [
    "# 实例化解析器、提示词模板\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"回答用户的查询.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# 使用LCEL语法组合一个简单的链\n",
    "prompt_and_model = prompt | llm\n",
    "\n",
    "# 调用模型并解析输出\n",
    "output = prompt_and_model.invoke({\"query\": \"给我讲一个笑话\"})\n",
    "print(\"Model output:\", output)\n",
    "\n",
    "try:\n",
    "    parsed_output = parser.invoke(output)\n",
    "    print(\"Parsed output:\", parsed_output)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to parse output: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: content='```json\\n{\\n  \"joke\": \"为什么电脑经常感冒？因为它总是开着窗户（Windows）！\"\\n}\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 17, 'total_tokens': 43, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 17}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': '7b1b74ce-0114-4cd3-8d20-2eec51ef3d51', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--84b0e994-0c80-464e-a3ac-038846b7c7ae-0' usage_metadata={'input_tokens': 17, 'output_tokens': 26, 'total_tokens': 43, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}}\n",
      "Parsed output (JSON format): {'joke': '为什么电脑经常感冒？因为它总是开着窗户（Windows）！'}\n"
     ]
    }
   ],
   "source": [
    "# 实例化解析器、提示词模板\n",
    "parser = JsonOutputParser()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"回答用户的查询.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# 使用LCEL语法组合一个简单的链\n",
    "prompt_and_model = prompt | llm\n",
    "\n",
    "# 调用模型并解析输出\n",
    "output = prompt_and_model.invoke({\"query\": \"给我讲一个笑话\"})\n",
    "print(\"Model output:\", output)\n",
    "\n",
    "try:\n",
    "    parsed_output = parser.parse(output.content)\n",
    "    print(\"Parsed output (JSON format):\", parsed_output)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to parse output: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action='tell_joke' action_input=''action='tell_joke' action_input='Why'action='tell_joke' action_input='Why do'action='tell_joke' action_input='Why do programmers'action='tell_joke' action_input='Why do programmers prefer'action='tell_joke' action_input='Why do programmers prefer dark'action='tell_joke' action_input='Why do programmers prefer dark mode'action='tell_joke' action_input='Why do programmers prefer dark mode?'action='tell_joke' action_input='Why do programmers prefer dark mode? Because'action='tell_joke' action_input='Why do programmers prefer dark mode? Because light'action='tell_joke' action_input='Why do programmers prefer dark mode? Because light attracts'action='tell_joke' action_input='Why do programmers prefer dark mode? Because light attracts bugs'action='tell_joke' action_input='Why do programmers prefer dark mode? Because light attracts bugs!'"
     ]
    }
   ],
   "source": [
    "# 使用LCEL语法组合一个简单的链\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "# 流式调用并逐个打印输出片段\n",
    "for s in chain.stream({\"query\": \"给我讲一个关于程序员编程的笑话\"}):\n",
    "    print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 LLM应用容错机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 正常流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='Answer the user query.\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"action\": {\"description\": \"action to take\", \"title\": \"Action\", \"type\": \"string\"}, \"action_input\": {\"description\": \"input to the action\", \"title\": \"Action Input\", \"type\": \"string\"}}, \"required\": [\"action\", \"action_input\"]}\\n```\\n北京天气如何？\\n'\n",
      "Model output: content='```json\\n{\\n  \"action\": \"tell_joke\",\\n  \"action_input\": \"为什么电脑很笨？因为它总是被人‘点’来‘点’去！\"\\n}\\n```' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 200, 'total_tokens': 239, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 192}, 'prompt_cache_hit_tokens': 192, 'prompt_cache_miss_tokens': 8}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_8802369eaa_prod0623_fp8_kvcache', 'id': 'aac6431f-afba-4ca8-a334-5cf78d94df9a', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--fd369b63-5c0a-4523-982f-0598e3e7b0a6-0' usage_metadata={'input_tokens': 200, 'output_tokens': 39, 'total_tokens': 239, 'input_token_details': {'cache_read': 192}, 'output_token_details': {}}\n",
      "Parsed output (JSON format): action='tell_joke' action_input='为什么电脑很笨？因为它总是被人‘点’来‘点’去！'\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Based on the user question, provide an Action and Action Input for what step should be taken.\n",
    "{format_instructions}\n",
    "Question: {query}\n",
    "Response:\"\"\"\n",
    "\n",
    "class Action(BaseModel):\n",
    "    action: str = Field(description=\"action to take\")\n",
    "    action_input: str = Field(description=\"input to the action\")\n",
    "parser = PydanticOutputParser(pydantic_object=Action)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "prompt_values = prompt.format_prompt(query=\"北京天气如何？\")\n",
    "print(prompt_values)\n",
    "\n",
    "# 使用LCEL语法组合一个简单的链\n",
    "prompt_and_model = prompt | llm\n",
    "\n",
    "# 调用模型并解析输出\n",
    "output = prompt_and_model.invoke({\"query\": \"给我讲一个笑话\"})\n",
    "print(\"Model output:\", output)\n",
    "\n",
    "try:\n",
    "    parsed_output = parser.parse(output.content)\n",
    "    print(\"Parsed output (JSON format):\", parsed_output)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to parse output: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RetryOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse output: Failed to parse Action from completion {\"action\": \"search\"}. Got: 1 validation error for Action\n",
      "action_input\n",
      "  Field required [type=missing, input_value={'action': 'search'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "\n",
      "parser=PydanticOutputParser(pydantic_object=<class '__main__.Action'>) retry_chain=PromptTemplate(input_variables=['completion', 'prompt'], input_types={}, partial_variables={}, template='Prompt:\\n{prompt}\\nCompletion:\\n{completion}\\n\\nAbove, the Completion did not satisfy the constraints given in the Prompt.\\nPlease try again:')\n",
      "| ChatDeepSeek(client=<openai.resources.chat.completions.completions.Completions object at 0x000001F4D413D280>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F4D413E660>, root_client=<openai.OpenAI object at 0x000001F4D5134E90>, root_async_client=<openai.AsyncOpenAI object at 0x000001F4D550AF30>, model_name='deepseek-chat', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), api_key=SecretStr('**********'), api_base='https://api.deepseek.com')\n",
      "| StrOutputParser()\n",
      "\n",
      "\n",
      "action='search' action_input='北京天气'\n"
     ]
    }
   ],
   "source": [
    "bad_response = '{\"action\": \"search\"}'\n",
    "try:\n",
    "    parsed_output = parser.parse(bad_response)\n",
    "    print(\"Parsed output (JSON format):\", parsed_output)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to parse output: {e}\\n\")\n",
    "    # 处理\n",
    "    retry_parser = RetryOutputParser.from_llm(\n",
    "        parser = parser,\n",
    "        llm=llm, # 可以更改新的llm\n",
    "    )\n",
    "    print(retry_parser)\n",
    "    print(\"\\n\")\n",
    "    print(retry_parser.parse_with_prompt(bad_response, prompt_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OutputFixingParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse output: Failed to parse Action from completion {\"action\": \"search\"}. Got: 1 validation error for Action\n",
      "action_input\n",
      "  Field required [type=missing, input_value={'action': 'search'}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "\n",
      "parser=PydanticOutputParser(pydantic_object=<class '__main__.Action'>) retry_chain=PromptTemplate(input_variables=['completion', 'error', 'instructions'], input_types={}, partial_variables={}, template='Instructions:\\n--------------\\n{instructions}\\n--------------\\nCompletion:\\n--------------\\n{completion}\\n--------------\\n\\nAbove, the Completion did not satisfy the constraints given in the Instructions.\\nError:\\n--------------\\n{error}\\n--------------\\n\\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:')\n",
      "| ChatDeepSeek(client=<openai.resources.chat.completions.completions.Completions object at 0x000001F4D2CE6570>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F4D3EF2180>, root_client=<openai.OpenAI object at 0x000001F4D2CE7AA0>, root_async_client=<openai.AsyncOpenAI object at 0x000001F4D3EF0890>, model_name='deepseek-chat', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), api_key=SecretStr('**********'), api_base='https://api.deepseek.com')\n",
      "| StrOutputParser()\n",
      "\n",
      "\n",
      "action='search' action_input='query'\n",
      "\n",
      "\n",
      "action='search' action_input='query'\n"
     ]
    }
   ],
   "source": [
    "bad_response = '{\"action\": \"search\"}'\n",
    "try:\n",
    "    parsed_output = parser.parse(bad_response)\n",
    "    print(\"Parsed output (JSON format):\", parsed_output)\n",
    "except Exception as e:\n",
    "    print(f\"Failed to parse output: {e}\\n\")\n",
    "    # 处理\n",
    "    fix_parser = OutputFixingParser.from_llm(\n",
    "        parser = parser,\n",
    "        llm=llm, # 可以更改新的llm\n",
    "    )\n",
    "    print(fix_parser)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(fix_parser.parse(bad_response))\n",
    "    print(\"\\n\")\n",
    "    print(fix_parser.parse_with_prompt(bad_response, prompt_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 'YES' to: True\n",
      "Parsed 'NO' to: False\n",
      "Error parsing 'MEOW': BooleanOutputParser expected output value to either be YES or NO (case-insensitive). Received MEOW.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "from langchain_core.output_parsers import BaseOutputParser  # 从 langchain_core 导入\n",
    "from langchain_core.exceptions import OutputParserException  # 从 langchain_core.exceptions 导入\n",
    "from pydantic import BaseModel, Field  # 导入 Pydantic 的 BaseModel 和 Field\n",
    "\n",
    "# 自定义布尔值解析器\n",
    "class BooleanOutputParser(BaseOutputParser[bool]):\n",
    "    \"\"\"Custom boolean parser.\"\"\"\n",
    "\n",
    "    # 定义 Pydantic 字段\n",
    "    true_val: str = Field(default=\"YES\", description=\"表示 True 的字符串\")\n",
    "    false_val: str = Field(default=\"NO\", description=\"表示 False 的字符串\")\n",
    "\n",
    "    def parse(self, text: str) -> bool:\n",
    "        \"\"\"\n",
    "        将输入的文本解析为布尔值。\n",
    "        \n",
    "        :param text: 输入的字符串。\n",
    "        :return: 解析后的布尔值。\n",
    "        :raises OutputParserException: 如果输入的字符串既不是 true_val 也不是 false_val。\n",
    "        \"\"\"\n",
    "        cleaned_text = text.strip().upper()  # 去除空格并转换为大写\n",
    "        if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):\n",
    "            raise OutputParserException(\n",
    "                f\"BooleanOutputParser expected output value to either be \"\n",
    "                f\"{self.true_val} or {self.false_val} (case-insensitive). \"\n",
    "                f\"Received {cleaned_text}.\"\n",
    "            )\n",
    "        return cleaned_text == self.true_val.upper()\n",
    "\n",
    "    @property\n",
    "    def _type(self) -> str:\n",
    "        \"\"\"\n",
    "        返回解析器的类型名称。\n",
    "        \n",
    "        :return: 解析器的类型名称。\n",
    "        \"\"\"\n",
    "        return \"boolean_output_parser\"\n",
    "\n",
    "# 测试解析器\n",
    "if __name__ == \"__main__\":\n",
    "    # 创建解析器实例\n",
    "    parser = BooleanOutputParser(true_val=\"YES\", false_val=\"NO\")\n",
    "\n",
    "    # 正常解析\n",
    "    try:\n",
    "        result = parser.parse(\"YES\")\n",
    "        print(f\"Parsed 'YES' to: {result}\")  # 输出: Parsed 'YES' to: True\n",
    "    except OutputParserException as e:\n",
    "        print(f\"Error parsing 'YES': {e}\")\n",
    "\n",
    "    try:\n",
    "        result = parser.parse(\"NO\")\n",
    "        print(f\"Parsed 'NO' to: {result}\")  # 输出: Parsed 'NO' to: False\n",
    "    except OutputParserException as e:\n",
    "        print(f\"Error parsing 'NO': {e}\")\n",
    "\n",
    "    # 错误解析\n",
    "    try:\n",
    "        result = parser.parse(\"MEOW\")\n",
    "        print(f\"Parsed 'MEOW' to: {result}\")\n",
    "    except OutputParserException as e:\n",
    "        print(f\"Error parsing 'MEOW': {e}\")  # 输出: Error parsing 'MEOW': ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
